{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['GROQ_API_KEY'] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The first person to land on the moon was Neil Armstrong, an astronaut from the United States. He was the commander of the Apollo 11 mission, which was the spaceflight that first landed humans on the moon on July 20, 1969. Armstrong\\'s famous words, \"That\\'s one small step for man, one giant leap for mankind,\" were spoken as he became the first person to set foot on the lunar surface.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 103, 'prompt_tokens': 16, 'total_tokens': 119, 'completion_time': 0.157697789, 'prompt_time': 0.002109172, 'queue_time': 0.030290798, 'total_time': 0.159806961}, 'model_name': 'mixtral-8x7b-32768', 'system_fingerprint': 'fp_c5f20b5bb1', 'finish_reason': 'stop', 'logprobs': None}, id='run-e96738b8-a607-4edc-b03f-c5822fbafe85-0', usage_metadata={'input_tokens': 16, 'output_tokens': 103, 'total_tokens': 119})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(temperature=0, model_name=\"mixtral-8x7b-32768\")\n",
    "\n",
    "llm.invoke(\"the first person to land on moon was\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='As a data science professor, I would like to explain the importance of low latency Large Language Models (LLMs) in the field of artificial intelligence and data science.\\n\\nLow latency refers to the ability of a system to process and respond to requests with minimal delay. In the context of LLMs, low latency is crucial for real-time applications such as chatbots, virtual assistants, and other interactive systems.\\n\\nHere are some reasons why low latency LLMs are important:\\n\\n1. Improved User Experience: Low latency LLMs can provide a more seamless and responsive user experience. Users expect quick and accurate responses from AI systems, and low latency LLMs can help meet these expectations.\\n2. Better Decision Making: In real-time applications, low latency LLMs can provide faster and more accurate insights, enabling better decision making. For example, in financial trading, low latency LLMs can help traders make quick and informed decisions based on real-time market data.\\n3. Increased Efficiency: Low latency LLMs can help increase the efficiency of AI systems by reducing the time it takes to process and respond to requests. This can lead to cost savings and improved productivity.\\n4. Enhanced Security: Low latency LLMs can help enhance the security of AI systems by reducing the time it takes to detect and respond to potential threats. This can help prevent data breaches and other security incidents.\\n5. Better Integration: Low latency LLMs can help improve the integration of AI systems with other applications and systems. This can enable more seamless workflows and improve overall system performance.\\n\\nIn summary, low latency LLMs are important for real-time applications in data science and artificial intelligence. They can provide a more responsive user experience, better decision making, increased efficiency, enhanced security, and better integration with other systems. As a data science professor, I would encourage students to consider the importance of low latency when designing and implementing AI systems.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 421, 'prompt_tokens': 26, 'total_tokens': 447, 'completion_time': 0.653605752, 'prompt_time': 0.002730377, 'queue_time': 0.026384783000000002, 'total_time': 0.656336129}, 'model_name': 'mixtral-8x7b-32768', 'system_fingerprint': 'fp_c5f20b5bb1', 'finish_reason': 'stop', 'logprobs': None}, id='run-5e03ae18-8d30-4d2b-987e-5f34069a3478-0', usage_metadata={'input_tokens': 26, 'output_tokens': 421, 'total_tokens': 447})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system = \"You are a data science professor.\"\n",
    "human = \"{text}\"\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", human)])\n",
    "\n",
    "chain = prompt | llm\n",
    "chain.invoke({\"text\": \"Explain the importance of low latency LLMs.\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
